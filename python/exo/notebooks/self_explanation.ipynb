{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71dbfa7f-6133-4bb6-be91-9e45b89c1b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8508f19-7080-43f1-b6b9-658dbf803fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton not installed, using eager implementation of SAE decoder.\n"
     ]
    }
   ],
   "source": [
    "import torch,safetensors,pathlib\n",
    "import huggingface_hub as hf_hub, safetensors as st\n",
    "from nnsight import LanguageModel\n",
    "from sae import Sae\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc4ca03-7e2b-41e0-916b-616df493e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(name:str,/,*,trust_remote_code:bool=False)->LanguageModel:\n",
    "  model = LanguageModel(name,device_map=\"auto\",\n",
    "                        trust_remote_code=trust_remote_code,\n",
    "                        low_cpu_mem_usage=True,torch_dtype=torch.float16)\n",
    "  model.requires_grad_(False)\n",
    "  return model\n",
    "\n",
    "def load_manual_sae(name:str,hookpoint:str):\n",
    "  repo_path = pathlib.Path(hf_hub.snapshot_download(name,allow_patterns=f\"{hookpoint}/*\"))\n",
    "  if not ((hookpath:=repo_path/hookpoint)/'cfg.json').exists(): raise FileNotFoundError(\"require cfg.json to specify a specific layers\")\n",
    "  with st.safe_open(str(hookpath/'sae_weights.safetensors'),\n",
    "                    framework='pt') as stf:\n",
    "    return stf.get_tensor('W_dec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afb4f816-f570-444e-a805-43070128bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Logic is easy, but it is impossible to be logical to bitter end. It is considered truth if one\"\n",
    "feature = 6689\n",
    "scale=20\n",
    "max_new_tokens=40\n",
    "num_return_sequences=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c9aa05-4085-4fc3-92bd-8ffdbff837e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb6a09180da41c0a3d956752899ebcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dropping extra args {'signed': False}\n"
     ]
    }
   ],
   "source": [
    "sae = Sae.load_from_hub(\"EleutherAI/sae-llama-3.1-8b-32x\", hookpoint=\"layers.29.mlp\")\n",
    "\n",
    "model = load_model(\"meta-llama/Meta-Llama-3.1-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2690df4a-3c51-4817-b175-0caba417dbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "  (generator): WrapperModule()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3dbf9f-c19a-4fa5-befd-e1db22c279b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    outputs = model(**inputs, output_hidden_states=True)\n",
    "    latent_acts = [sae.encode(outputs.hidden_states[29])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9d3b1-ddf7-4600-b004-ad09d2c69d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bce6ce-2c63-473a-9666-0fb2a707ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=latent_acts[0]\n",
    "l.top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddc2cbbf-d0c3-4907-bfd4-662403d1bc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0091, -0.0137, -0.0124,  ...,  0.0023,  0.0068, -0.0111]],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.W_dec[[6689]] # feature index: logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f41ea6b1-58f4-40ad-9ccb-c4854f32f78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m       \u001b[0msae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m            Sae\n",
       "\u001b[0;31mString form:\u001b[0m    \n",
       "Sae(\n",
       "  (encoder): Linear(in_features=4096, out_features=131072, bias=True)\n",
       ")\n",
       "\u001b[0;31mFile:\u001b[0m            ~/workspace/capstone/.venv/lib/python3.12/site-packages/sae/sae.py\n",
       "\u001b[0;31mDocstring:\u001b[0m       <no docstring>\n",
       "\u001b[0;31mClass docstring:\u001b[0m\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool\n",
       "\u001b[0;31mInit docstring:\u001b[0m  Initialize internal Module state, shared by both nn.Module and ScriptModule."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sae?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6471b16-970d-4f46-9860-ed397ee34459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
